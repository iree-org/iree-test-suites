### Example LLaMa Model with Toy Implementation

The LLaMa example contained is a random initiated model with 3 layers. The
motivation is to have an executable version of the model to validate both
compilation and numerics of execution. This is generated using using sharktank
with the default coefficients. Future updates for the `mlir` file should
maintain the same `irpa` values while only updating the executed code.

This files are generated by the following

```bash
git clone https://github.com/nod-ai/shark-ai.git

cd shark-ai/sharktank
python3 -m pip install .

cd ..

# Generate the IRPA files:
python3 -m sharktank.models.llama.toy_llama --output toy_llama.irpa
python3 -m sharktank.examples.sharding.shard_llm_dataset \
    --irpa-file toy_llama.irpa \
    --tensor-parallelism-size 2 \
    --output-irpa-file toy_llama_tp2.irpa


# Generate the MLIR files:
python3 -m sharktank.examples.export_paged_llm_v1 \
    --bs-prefill=1 \
    --bs-decode=1 \
    --irpa-file toy_llama.irpa --output-mlir toy_llama.mlir
python3 -m sharktank.examples.export_paged_llm_v1 \
    --bs-prefill=1 \
    --bs-decode=1 \
    --irpa-file toy_llama_tp2.irpa --output-mlir toy_llama_tp2.mlir

# Generate the MLIR files for the batched tests
python3 -m sharktank.examples.export_paged_llm_v1 \
    --bs-prefill=1 \
    --bs-decode=1 \
    --irpa-file toy_llama.irpa --output-mlir asssets/bs1/toy_llama_bs1.mlir

python3 -m sharktank.examples.export_paged_llm_v1 \
    --bs-prefill=4 \
    --bs-decode=4 \
    --irpa-file toy_llama.irpa --output-mlir asssets/bs1/toy_llama_bs4.mlir

python3 -m sharktank.examples.export_paged_llm_v1 \
    --bs-prefill=32 \
    --bs-decode=32 \
    --irpa-file toy_llama.irpa --output-mlir asssets/bs1/toy_llama_bs32.mlir
```
